# -*- coding: utf-8 -*-
"""Colab 4 - Building a Convolutional Neural Network in TensorFlow 2.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M90124HfEO_zORhbVDdFeDMHV743eJmc

## Step 1: Installing dependencies and notebook gpu setup
"""


"""## Step 2: Importing the libraries"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import matplotlib.pyplot as plt

from tensorflow.keras.datasets import cifar10

# %matplotlib inline
tf.__version__

"""## Step 3: Data Preprocessing

### Loading the Cifar10 dataset
"""

# Setting class names in the dataset
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

# Loading the dataset
(X_train, y_train), (X_test, y_test) = cifar10.load_data()

"""### Image normalization"""

X_train = X_train / 255.0

X_train.shape

X_test = X_test / 255.0

plt.imshow(X_test[10])

"""## Step 4: Building a Convolutional Neural Network

### Defining the model
"""

model = tf.keras.models.Sequential()

"""### Adding the first convolutional layer

CNN layer hyper-parameters:
- filters: 32
- kernel_size: 3
- padding: same
- activation: relu
- input_shape: (32, 32, 3)

"""

model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding="same", activation="relu", input_shape=[32, 32, 3]))

"""### Adding the second convolutional layer and the max-pooling layer

CNN layer hyper-parameters:
- filters: 32
- kernel_size:3
- padding: same
- activation: relu

MaxPool layer hyper-parameters:
- pool_size: 2
- strides: 2
- padding: valid
"""

model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding="same", activation="relu"))

model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))

"""### Adding the third convolutional layer

CNN layer hyper-parameters:

    filters: 64
    kernel_size:3
    padding: same
    activation: relu

"""

model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding="same", activation="relu"))

"""###  Adding the fourth convolutional layer and max-pooling layer

CNN layer hyper-parameters:

    filters: 64
    kernel_size:3
    padding: same
    activation: relu

MaxPool layer hyper-parameters:

    pool_size: 2
    strides: 2
    padding: valid

"""

model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding="same", activation="relu"))

model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))

"""### Adding the flattening layer"""

model.add(tf.keras.layers.Flatten())

"""### Adding the first fully-connected layer

Dense layer hyper-parameters:
- units/neurons: 128
- activation: relu
"""

model.add(tf.keras.layers.Dense(units=128, activation='relu'))

"""### Adding the output layer

Dense layer hyper-parameters:

 - units/neurons: 10 (number of classes)
 - activation: softmax

"""

model.add(tf.keras.layers.Dense(units=10, activation='softmax'))

model.summary()

"""### Compiling the model

#### sparse_categorical_accuracy
sparse_categorical_accuracy checks to see if the maximal true value is equal to the index of the maximal predicted value.

https://stackoverflow.com/questions/44477489/keras-difference-between-categorical-accuracy-and-sparse-categorical-accuracy
"""

model.compile(loss="sparse_categorical_crossentropy", optimizer="Adam", metrics=["sparse_categorical_accuracy"])

"""### Training the model"""

model.fit(X_train, y_train, epochs=5)

"""### Evaluating the model"""

test_loss, test_accuracy = model.evaluate(X_test, y_test)

print("Test accuracy: {}".format(test_accuracy))
model.save('my_model.keras')